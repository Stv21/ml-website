<!DOCTYPE html>
<html>
<head>
    <title>Boosting (heart.csv)</title>
    <meta charset="UTF-8">
</head>
<body>
<pre>
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.metrics import accuracy_score, classification_report
from google.colab import drive

# 1. Mount Google Drive and Load Data
drive.mount('/content/drive')
file_path = "/content/drive/My Drive/heart.csv" 
try:
    df = pd.read_csv(file_path)
except FileNotFoundError:
    print(f"Error: File not found at {file_path}")
    exit()
print("Data loaded successfully.")

# 2. Prepare Data
df.dropna(inplace=True)
numeric_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']
categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']
target = 'target'
X = df[numeric_features + categorical_features]
y = df[target]

# 3. Split Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4. Preprocessing Pipeline
# Like Random Forest, Gradient Boosting does NOT need StandardScaler
categorical_transformer = OneHotEncoder(handle_unknown='ignore')
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', categorical_transformer, categorical_features)
    ],
    remainder='passthrough'
)

# 5. Apply Preprocessing
X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

# 6. Initialize and Train Model (Gradient Boosting)
# n_estimators = number of sequential trees
# learning_rate = how much each tree corrects the previous one's errors
model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
model.fit(X_train_processed, y_train)

# 7. Evaluate Model
y_pred = model.predict(X_test_processed)
accuracy = accuracy_score(y_test, y_pred)
print(f"\nModel Performance (Gradient Boosting):")
print(f"Accuracy: {accuracy:.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
</pre>
<br>
<p><a href="index.html">&larr; Back to Dataset Selection</a></p>
</body>
</html>
